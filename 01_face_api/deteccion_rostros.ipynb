{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/intro_01.png)\n",
    "\n",
    "# Detección de intrusos\n",
    "\n",
    "## Objetivo\n",
    "\n",
    "Este notebook tiene como objetivo mostrar el uso del servicio cognitivo **Face API de Microsoft Azure** para generar una \"base de datos\" de rostros y después comparar nuevos rostros. \n",
    "\n",
    "## Temas\n",
    "\n",
    "1. Activación del servicio en el portal Azure\n",
    "2. Creación de base de datos y usuario\n",
    "3. Carga de información a la base de datos\n",
    "4. Comparación de nuevos rostros\n",
    "\n",
    "## Requisitos\n",
    "\n",
    "- Cuenta de Azure\n",
    "- Python 3.x\n",
    "- Librerias:\n",
    "    - requests\n",
    "    - os\n",
    "    - time\n",
    "\n",
    "## 1. Activación del servicio en el portal Azure\n",
    "\n",
    "1. Ingresar a la dirección [portal.azure.com](https://portal.azure.com)\n",
    "\n",
    "2. Buscar **Cognitive services**\n",
    "\n",
    "![](imgs/paso_01.png)\n",
    "\n",
    "3. Seleccionar **Add**\n",
    "\n",
    "![](imgs/paso_02.png)\n",
    "\n",
    "4. Buscar el servicio de su elección. En este caso es **Face**\n",
    "\n",
    "![](imgs/paso_03.png)\n",
    "\n",
    "5. Seleccionar **Create**\n",
    "\n",
    "![](imgs/paso_04.png)\n",
    "\n",
    "6. Llenar el formulario con la información solicitada y seleccionar **Create**.\n",
    "\n",
    "Un ejemplo sería:\n",
    "    - Name: deteccion-intruso\n",
    "    - Subscription: Azure for Students\n",
    "    - Location: (US) East US 2\n",
    "    - Pricing tier: S0 (10 Calls per Second)\n",
    "    - Resource group: clase_azure_unam\n",
    "    \n",
    "![](imgs/paso_05.png)\n",
    "\n",
    "7. Esperar alrededor de un mintuo hasta que indique que el \"despliegue\" del servicio está completo. Seleccionar **Go to resource**.\n",
    "\n",
    "![](imgs/paso_06.png)\n",
    "\n",
    "8. En esta sección se pueden observar tanto el **key** como el **endpoint**, los cuales son necesarios para realizar los llamados al API.\n",
    "\n",
    "![](imgs/paso_07.png)\n",
    "\n",
    "9. Copiar y guardar la información de **key** y **endpoint** para usarlo en python.\n",
    "\n",
    "En este ejemplo se creó un archivo **conf_param.py** que contiene la siguiente información\n",
    "\n",
    "```python\n",
    "KEY = 'key'\n",
    "BASE_URL = 'endpoint'\n",
    "```\n",
    "\n",
    "10. Guardar el archivo en la misma ubicación que este notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creación de la base de datos y usuarios\n",
    "\n",
    "Una vez hemos desplegado el servicio cognitivo **Face API** y contamos con la **key** y **endpoint** del mismo, procedemos a abrir una consola de jupyter notebook para comenzar a configurar la base de datos que almacenará las imágenes que utilizaremos para determinar si una persona tiene permitido el acceso o no.\n",
    "\n",
    "Para este tutorial se utiliará información proveniente de la documentación de Microsoft para [Face API](https://westus.dev.cognitive.microsoft.com/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395236)\n",
    "\n",
    "1. Cargar las librerias e información a utilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, os, time\n",
    "KEY = ''\n",
    "END_POINT = ''\n",
    "BASE_URL = END_POINT+'/face/v1.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Definimos el nombre de la base de datos a utilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_base = 'demo_intrusos'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Procedemos a crear la base de datos\n",
    "\n",
    "Para esto, se utilizará la sección de **LargePersonGroup** mostrada en la [documentación](https://westus.dev.cognitive.microsoft.com/docs/services/563879b61984550e40cbbe8d/operations/599acdee6ac60f11b48b5a9d)\n",
    "\n",
    "A continuación se muestra una parte de dicha documentación donde nos explica los parámetros a utilizar.\n",
    "\n",
    "### LargePersonGroup - Create\n",
    "\n",
    "Create a new large person group with user-specified largePersonGroupId, name, an optional userData and recognitionModel.\n",
    "A large person group is a container holding the uploaded person data, including the face recognition features. It can hold up to 1,000,000 entities.\n",
    "After creation, use LargePersonGroup Person - Create to add person into the group, and call LargePersonGroup - Train to get this group ready for Face - Identify.\n",
    "No image will be stored. Only the person's extracted face feature(s) and userData will be stored on server until LargePersonGroup Person - Delete or LargePersonGroup - Delete is called.\n",
    "\n",
    "'recognitionModel' should be specified to associate with this large person group. The default value for 'recognitionModel' is 'recognition_01', if the latest model needed, please explicitly specify the model you need in this parameter. New faces that are added to an existing large person group will use the recognition model that's already associated with the collection. Existing face feature(s) in a large person group can't be updated to features extracted by another version of recognition model.\n",
    "\n",
    "* 'recognition_01': The default recognition model for LargePersonGroup - Create. All those large person groups created before 2019 March are bonded with this recognition model.\n",
    "* 'recognition_02': Recognition model released in 2019 March. 'recognition_02' is recommended since its overall accuracy is improved compared with 'recognition_01'.\n",
    "\n",
    "Large person group quota:\n",
    "* Free-tier subscription quota: 1,000 large person groups.\n",
    "* S0-tier subscription quota: 1,000,000 large person groups.\n",
    "\n",
    "#### Http Method\n",
    "\n",
    "PUT\n",
    "\n",
    "#### Request URL\n",
    "\n",
    "https://{endpoint}/face/v1.0/largepersongroups/{largePersonGroupId}\n",
    "\n",
    "#### Request parameters\n",
    "\n",
    "| Field | Type | Description |\n",
    "|:--- |:---:|:--- |\n",
    "|largePersonGroupId | string | User-provided largePersonGroupId as a string. The valid characters include numbers, English letters in lower case, '-' and '_'. The maximum length of the largePersonGroupId is 64. |\n",
    "\n",
    "#### Request headers\n",
    "\n",
    "| Field | Type | Description |\n",
    "|:--- |:---:|:--- |\n",
    "| Content-Type | string | Media type of the body sent to the API. |\n",
    "| Ocp-Apim-Subscription-Key | string | Subscription key which provides access to this API. Found in your Cognitive Services accounts. |\n",
    "\n",
    "#### Request body\n",
    "\n",
    "JSON fields in request body:\n",
    "\n",
    "| Fields | Type | Description |\n",
    "|:--- |:---:|:--- |\n",
    "| name | String | Name of the created large person group, maximum length is 128. |\n",
    "| userData (optional) | String | Optional user defined data for the large person group. Length should not exceed 16KB. |\n",
    "| recognitionModel (optional) | String | The 'recognitionModel' associated with this large person group. Supported 'recognitionModel' values include \"recognition_01\" and \"recognition_02\". The default value is \"recognition_01\". \"recognition_02\" is recommended since its overall accuracy is improved compared with \"recognition_01\". | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-629b82837688>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m response = requests.request(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;31m#method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;34m'PUT'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m#url\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mBASE_URL\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/largepersongroups/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnombre_base\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "response = requests.request(\n",
    "    #method\n",
    "    'PUT',\n",
    "    #url\n",
    "    BASE_URL + '/largepersongroups/' + nombre_base,\n",
    "    #json\n",
    "    json = {'name': nombre_base,\n",
    "            'recognitionModel': 'recognition_02'},\n",
    "    #headers\n",
    "    headers = {'Content-Type': 'application/json',\n",
    "               'Ocp-Apim-Subscription-Key': KEY}\n",
    ")\n",
    "\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. El código anterior debe dar como resultado un **200**. En caso contrario validar los pasos previos.\n",
    "\n",
    "5. Podemos confirmar que la base se creo de forma correcta solicitando la lista de todas las bases de datos.\n",
    "\n",
    "### LargePersonGroup - List\n",
    "\n",
    "List all existing large person groups’s largePersonGroupId, name, userData and recognitionModel.\n",
    "* Large person groups are stored in alphabetical order of largePersonGroupId.\n",
    "* \"start\" parameter (string, optional) is a user-provided largePersonGroupId value that returned entries have larger ids by string comparison. \"start\" set to empty to indicate return from the first item.\n",
    "* \"top\" parameter (int, optional) specifies the number of entries to return. A maximal of 1000 entries can be returned in one call. To fetch more, you can specify \"start\" with the last retuned entry’s Id of the current call.\n",
    "\n",
    "For example, total 5 large person groups: \"group1\", ..., \"group5\".\n",
    "\"start=&top=\" will return all 5 groups.\n",
    "\"start=&top=2\" will return \"group1\", \"group2\".\n",
    "\"start=group2&top=3\" will return \"group3\", \"group4\", \"group5\".\n",
    "\n",
    "#### Http Method\n",
    "\n",
    "GET\n",
    "\n",
    "#### Request URL\n",
    "\n",
    "https://{endpoint}/face/v1.0/largepersongroups[?start][&top][&returnRecognitionModel]\n",
    "\n",
    "#### Request parameters\n",
    "\n",
    "| Field | Type | Description |\n",
    "|:--- |:---:|:--- |\n",
    "| start (optional) | string | List large person groups from the least largePersonGroupId greater than the \"start\". It contains no more than 64 characters. Default is empty. |\n",
    "| top (optional) | integer | The number of large person groups to list, ranging in [1, 1000]. Default is 1000. |\n",
    "| returnRecognitionModel (optional) | boolean | Return 'recognitionModel' or not. The default value is false. |\n",
    "\n",
    "#### Request headers\n",
    "\n",
    "| Field | Type | Description |\n",
    "|:--- |:---:|:--- |\n",
    "| Ocp-Apim-Subscription-Key | string | Subscription key which provides access to this API. Found in your Cognitive Services accounts. |\n",
    "\n",
    "#### Request body\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.request(\n",
    "    #method\n",
    "    'GET',\n",
    "    #url\n",
    "    BASE_URL + '/largepersongroups/',\n",
    "    #params\n",
    "    params = {'returnRecognitionModel': True},\n",
    "    #headers\n",
    "    headers = {'Content-Type': 'application/json',\n",
    "               'Ocp-Apim-Subscription-Key': KEY}\n",
    ")\n",
    "\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. El código anterior debe dar como resultado un **200**. De tal forma que podemos ver la información que regresa como se muestra a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'recognitionModel': 'recognition_02',\n",
       "  'largePersonGroupId': 'demo_intrusos',\n",
       "  'name': 'demo_intrusos',\n",
       "  'userData': None}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. También podemos verificar el status de la base para saber si ya ha sido entrenada o no.\n",
    "\n",
    "### LargePersonGroup - Get Training Status\n",
    "\n",
    "To check large person group training status completed or still ongoing. LargePersonGroup Training is an asynchronous operation triggered by LargePersonGroup - Train API.\n",
    "\n",
    "Training time depends on the number of person entries, and their faces in a large person group. It could be in seconds, or up to half an hour for 1,000,000 persons.\n",
    "\n",
    "#### Http Method\n",
    "\n",
    "GET\n",
    "\n",
    "#### Request URL\n",
    "\n",
    "https://{endpoint}/face/v1.0/largepersongroups/{largePersonGroupId}/training\n",
    "\n",
    "#### Request parameters\n",
    "\n",
    "| Field | Type | Description |\n",
    "|:--- |:---:|:--- |\n",
    "|largePersonGroupId | string | LargePersonGroupId of target person group. |\n",
    "\n",
    "#### Request headers\n",
    "\n",
    "| Field | Type | Description |\n",
    "|:--- |:---:|:--- |\n",
    "| Ocp-Apim-Subscription-Key | string | Subscription key which provides access to this API. Found in your Cognitive Services accounts. |\n",
    "\n",
    "#### Request body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.request(\n",
    "    #method\n",
    "    'GET',\n",
    "    #url\n",
    "    BASE_URL + '/largepersongroups/' + nombre_base + '/training',\n",
    "    #headers\n",
    "    headers = {'Ocp-Apim-Subscription-Key': KEY}\n",
    ")\n",
    "\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. El código anterior debe dar como resultado un **404** ya que aún no ha sido entrenado (una vez lo entrenemos debe dar un 200). De tal forma que podemos ver la información que regresa como se muestra a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error': {'code': 'LargePersonGroupNotTrained',\n",
       "  'message': 'Large person group not trained.'}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Para comenzar a cargar información a la base de datos es necesario crear un \"contenedor\" por cada usuario/persona para que pueda almacenar sus rostros.\n",
    "\n",
    "### LargePersonGroup Person - Create\n",
    "\n",
    "Create a new person in a specified large person group. To add face to this person, please call LargePersonGroup PersonFace - Add.\n",
    "\n",
    "- Free-tier subscription quota:\n",
    "    - 1,000 persons in all large person groups.\n",
    "- S0-tier subscription quota:\n",
    "    - 1,000,000 persons per large person group.\n",
    "    - 1,000,000 large person groups.\n",
    "    - 1,000,000,000 persons in all large person groups.\n",
    "\n",
    "### Http Method\n",
    "POST\n",
    "\n",
    "### Request URL\n",
    "https://{endpoint}/face/v1.0/largepersongroups/{largePersonGroupId}/persons\n",
    "\n",
    "### Request parameters\n",
    "\n",
    "| Field | Type | Description |\n",
    "|:--- |:---:|:--- |\n",
    "| largePersonGroupId | string | largePersonGroupId of the target large person group. |\n",
    "\n",
    "### Request headers\n",
    "\n",
    "| Field | Type | Description |\n",
    "|:--- |:---:|:--- |\n",
    "| Content-Type | string | Media type of the body sent to the API. |\n",
    "| Ocp-Apim-Subscription-Key | string | Subscription key which provides access to this API. Found in your Cognitive Services accounts. |\n",
    "\n",
    "### Request body\n",
    "\n",
    "JSON fields in request body:\n",
    "\n",
    "| Field | Type | Description |\n",
    "|:--- |:---:|:--- |\n",
    "| name | String | Name of the created person, maximum length is 128. |\n",
    "| userData (optional) | String | Optional user defined data for the person. Length should not exceed 16KB. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usuario = 'usuario_demo'\n",
    "\n",
    "response = requests.request(\n",
    "    #method\n",
    "    'POST',\n",
    "    #url\n",
    "    BASE_URL + '/largepersongroups/' + nombre_base + '/persons/',\n",
    "    #json\n",
    "    json = {'name': usuario},\n",
    "    #headers\n",
    "    headers = {'Content-Type': 'application/json',\n",
    "               'Ocp-Apim-Subscription-Key': KEY}\n",
    ")\n",
    "\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. En este caso es necesario guardar la respuesta del \"request\" ya que nos regresa información sobre el ID asociado al usuario. Esta información es necesaria para cargar los rostros relacionados con el usuario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'personId': '8684eddf-c898-47ee-ac6e-98c56eb3c1d9'}\n"
     ]
    }
   ],
   "source": [
    "print(response.json())\n",
    "\n",
    "personId = response.json()['personId']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Otra forma de obtener esta información es mediante la consulta de todos los usuarios pertenecientes a la base de datos\n",
    "\n",
    "### LargePersonGroup Person - List\n",
    "\n",
    "List all persons’ information in the specified large person group, including personId, name, userData and persistedFaceIds of registered person faces.\n",
    "- Persons are stored in alphabetical order of personId created in LargePersonGroup Person - Create.\n",
    "- \"start\" parameter (string, optional) is a personId value that returned entries have larger ids by string comparison. \"start\" set to empty to indicate return from the first item.\n",
    "- \"top\" parameter (int, optional) specifies the number of entries to return. A maximal of 1000 entries can be returned in one call. To fetch more, you can specify \"start\" with the last returned entry’s personId of the current call.\n",
    "\n",
    "For example, total 5 persons with their personId: \"personId1\", ..., \"personId5\".\n",
    "\"start=&top=\" will return all 5 persons.\n",
    "\"start=&top=2\" will return \"personId1\", \"personId2\".\n",
    "\"start=personId2&top=3\" will return \"personId3\", \"personId4\", \"personId5\".\n",
    "\n",
    "#### Http Method\n",
    "GET\n",
    "\n",
    "#### Request URL\n",
    "\n",
    "https://{endpoint}/face/v1.0/largepersongroups/{largePersonGroupId}/persons[?start][&top]\n",
    "\n",
    "#### Request parameters\n",
    "\n",
    "| Field | Type | Description |\n",
    "|:--- |:---:|:--- |\n",
    "|largePersonGroupId | string | largePersonGroupId of the target large person group. |\n",
    "| start (optional) | string | List persons from the least personId greater than the \"start\". It contains no more than 64 characters. Default is empty. |\n",
    "| top (optional) | integer | The number of persons to list, ranging in [1, 1000]. Default is 1000. |\n",
    "\n",
    "#### Request headers\n",
    "\n",
    "| Field | Type | Description |\n",
    "|:--- |:---:|:--- |\n",
    "| Ocp-Apim-Subscription-Key | string | Subscription key which provides access to this API. Found in your Cognitive Services accounts. |\n",
    "\n",
    "#### Request body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.request(\n",
    "    #method\n",
    "    'GET',\n",
    "    #url\n",
    "    BASE_URL + '/largepersongroups/' + nombre_base + '/persons',\n",
    "    #headers\n",
    "    headers = {'Content-Type': 'application/json',\n",
    "               'Ocp-Apim-Subscription-Key': KEY}\n",
    ")\n",
    "\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y obtenemos la información de los usuarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'personId': '8684eddf-c898-47ee-ac6e-98c56eb3c1d9',\n",
       "  'persistedFaceIds': [],\n",
       "  'name': 'usuario_demo',\n",
       "  'userData': None}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Una vez creado el \"contenedor\" para el usuario, es necesario cargar la base de datos con los vectores de características de los rostros. Es decir, necesitamos cargar las imágenes al API para que las procese.\n",
    "\n",
    "### LargePersonGroup Person - Add Face\n",
    "\n",
    "Add a face to a person into a large person group for face identification or verification. To deal with an image containing multiple faces, input face can be specified as an image with a targetFace rectangle. It returns a persistedFaceId representing the added face. No image will be stored. Only the extracted face feature(s) will be stored on server until LargePersonGroup PersonFace - Delete, LargePersonGroup Person - Delete or LargePersonGroup - Delete is called.\n",
    "Note persistedFaceId is different from faceId generated by Face - Detect.\n",
    "- Higher face image quality means better recognition precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.\n",
    "- Each person entry can hold up to 248 faces.\n",
    "- JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\n",
    "- \"targetFace\" rectangle should contain one face. Zero or multiple faces will be regarded as an error. If the provided \"targetFace\" rectangle is not returned from Face - Detect, there’s no guarantee to detect and add the face successfully.\n",
    "- Out of detectable face size (36x36 - 4096x4096 pixels), large head-pose, or large occlusions will cause failures.\n",
    "- Adding/deleting faces to/from a same person will be processed sequentially. Adding/deleting faces to/from different persons are processed in parallel.\n",
    "- The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\n",
    "- Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to How to specify a detection model\n",
    "    - 'detection_01': The default detection model for LargePersonGroup Person - Add Face. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\n",
    "    - 'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces.\n",
    "\n",
    "#### Http Method\n",
    "\n",
    "POST\n",
    "\n",
    "#### Request URL\n",
    "\n",
    "https://{endpoint}/face/v1.0/largepersongroups/{largePersonGroupId}/persons/{personId}/persistedfaces[?userData][&targetFace][&detectionModel]\n",
    "\n",
    "#### Request parameters\n",
    "\n",
    "| Field | Type | Description |\n",
    "|:--- |:---:|:--- |\n",
    "| largePersonGroupId | string | largePersonGroupId of the target large person group. |\n",
    "| personId | string | personId of the target person. |\n",
    "| userData (optional) | string | User-specified data about the target face to add for any purpose. The maximum length is 1KB. |\n",
    "| targetFace (optional) | string | A face rectangle to specify the target face to be added to a person, in the format of \"targetFace=left,top,width,height\". E.g. \"targetFace=10,10,100,100\". If there is more than one face in the image, targetFace is required to specify which face to add. No targetFace means there is only one face detected in the entire image. |\n",
    "| detectionModel (optional) | string | The 'detectionModel' associated with the detected faceIds. Supported 'detectionModel' values include \"detection_01\" or \"detection_02\". The default value is \"detection_01\". |\n",
    "\n",
    "#### Request headers\n",
    "\n",
    "| Field | Type | Description |\n",
    "|:--- |:---:|:--- |\n",
    "| Content-Type | string | Media type of the body sent to the API. |\n",
    "| Ocp-Apim-Subscription-Key | string | Subscription key which provides access to this API. Found in your Cognitive Services accounts. |\n",
    "\n",
    "#### Request body\n",
    "\n",
    "JSON fields in request body:\n",
    "\n",
    "| Field | Type | Description |\n",
    "|:--- |:---:|:--- |\n",
    "| url | String | Face image URL. Valid image size is from 1KB to 6MB. Only one face is allowed per image. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.request(\n",
    "    #method\n",
    "    'POST',\n",
    "    #url\n",
    "    BASE_URL + '/largepersongroups/' + nombre_base + '/persons/' + personId + '/persistedFaces',\n",
    "    # params\n",
    "    params = {'detectionModel': 'detection_02'},\n",
    "    #data\n",
    "    data = open('foto_07.jpg', 'rb').read(),\n",
    "    #headers\n",
    "    headers = {'Content-Type': 'application/octet-stream',\n",
    "               'Ocp-Apim-Subscription-Key': KEY}\n",
    ")\n",
    "\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Al regresarnos un código **200** sabemos que la identificación del rostro y extracción del vector de características se realizo correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Ejemplo/Ejercicio\n",
    "\n",
    "Se creará una base de datos de nombre 'games_of_thrones' y se cargarán las imágenes contenidas en la carpeta de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finaliza la carga de las fotos de emilia_clarke\n",
      "Finaliza la carga de las fotos de kit_harington\n",
      "Finaliza la carga de las fotos de peter_dinklage\n",
      "Finaliza la carga de las fotos de sophie_turner\n",
      "Finaliza la carga de las fotos de vladimir_furdik\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'personId': '0ec895a7-3a1e-47fb-9b3a-576d5c58f91e',\n",
       "  'persistedFaceIds': ['08c25e6a-5373-4a92-a1cd-f0c3c8140a71',\n",
       "   '0d267a17-ca2b-455d-899c-4afc6b2286d9',\n",
       "   '1d891b2d-32cb-4e7c-9cba-2d6ecabef826',\n",
       "   '21f9feda-2c64-44d1-928d-e3ac64248f5b',\n",
       "   '2d341c97-d9b0-4393-8b39-87242395c2e8'],\n",
       "  'name': 'kit_harington',\n",
       "  'userData': None},\n",
       " {'personId': '19ba06ce-cba2-4ded-9bc5-b42d428f2051',\n",
       "  'persistedFaceIds': ['1519633d-71d3-4757-be3d-c525b3553098',\n",
       "   '1d6c8c5e-b4ac-4644-a360-fcd9154571e1',\n",
       "   '1e2e0000-face-4bc9-8870-b676bd8e7c8c',\n",
       "   '76889b5c-49c5-4d21-b3b6-238e6f90e2f7'],\n",
       "  'name': 'peter_dinklage',\n",
       "  'userData': None},\n",
       " {'personId': '326788e9-f210-4c32-835a-246d018efe83',\n",
       "  'persistedFaceIds': ['2d252fe9-efed-42bb-b590-5b7a58e6711a',\n",
       "   '5655e1d8-387a-4b18-afd6-2eb77978ab2d',\n",
       "   'adca698b-3866-4291-87ed-915605d16faf',\n",
       "   'c9c910cf-ec0a-4ea6-a164-a63cf9be1398',\n",
       "   'f2a03313-fe9b-4771-8cff-895e8d48d0b8'],\n",
       "  'name': 'emilia_clarke',\n",
       "  'userData': None},\n",
       " {'personId': '66a70c0e-c640-4891-9f71-1d13d88c8caf',\n",
       "  'persistedFaceIds': ['489db1ce-f6e6-42a1-97cf-a593c6e831a7',\n",
       "   '5127c672-1ec4-46b3-9215-a23497e7a1dc',\n",
       "   '62ca3b91-f1f1-49d8-bbb2-8860eb6288c5',\n",
       "   'b34c1005-6dbf-43bd-ab5c-352cb927bb1b',\n",
       "   'c8eb126c-9674-4d27-8344-649a894c964b'],\n",
       "  'name': 'sophie_turner',\n",
       "  'userData': None},\n",
       " {'personId': 'a87896ad-8369-4834-8864-fbcfcbfd4a87',\n",
       "  'persistedFaceIds': ['46d958f1-872e-48c0-bf99-33cb4e4fdc49',\n",
       "   '56d98200-e0e2-471f-b4b9-d4b762c8d5cc',\n",
       "   'acbe07a6-1704-428a-ad6c-1f3b029b522d',\n",
       "   'cf1dec18-3e1b-485c-8683-ad910dff1af5',\n",
       "   'fed30f55-ddd8-40bf-83b9-b9c5001da713'],\n",
       "  'name': 'vladimir_furdik',\n",
       "  'userData': None},\n",
       " {'personId': 'e0d2116e-9627-44d8-976d-50e065055b29',\n",
       "  'persistedFaceIds': ['1c3801a3-6381-4914-8284-c5cdc4771dfe',\n",
       "   '3750a823-cc98-45df-a64c-222e8e7205fc',\n",
       "   '83543452-27ba-431b-9d61-4c51213af3a2',\n",
       "   '8cd5f718-d911-4b54-a3e0-f84e61043d9a',\n",
       "   'b2b03769-87b4-40cd-8795-bf55fae7e8fe'],\n",
       "  'name': 'emilia_clarke',\n",
       "  'userData': None}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se crea la base de datos\n",
    "nombre_base = 'games_of_thrones'\n",
    "requests.request(\n",
    "    #method\n",
    "    'PUT',\n",
    "    #url\n",
    "    BASE_URL + '/largepersongroups/' + nombre_base,\n",
    "    #json\n",
    "    json = {'name': nombre_base,\n",
    "            'recognitionModel': 'recognition_02'},\n",
    "    #headers\n",
    "    headers = {'Content-Type': 'application/json',\n",
    "               'Ocp-Apim-Subscription-Key': KEY}\n",
    ")\n",
    "\n",
    "# Se genera la lista de usuarios\n",
    "path_usuario = 'base_rostros/entrenamiento/'\n",
    "usuarios = os.listdir(path_usuario)\n",
    "\n",
    "for usuario in usuarios:\n",
    "    response = requests.request(\n",
    "        #method\n",
    "        'POST',\n",
    "        #url\n",
    "        BASE_URL + '/largepersongroups/' + nombre_base + '/persons/',\n",
    "        #json\n",
    "        json = {'name': usuario},\n",
    "        #headers\n",
    "        headers = {'Content-Type': 'application/json',\n",
    "                   'Ocp-Apim-Subscription-Key': KEY}\n",
    "    )\n",
    "    \n",
    "    personId = response.json()['personId']\n",
    "    \n",
    "    # Se genera la lista de fotos del usuario\n",
    "    path_img = path_usuario + usuario + '/'\n",
    "    fotos = list(filter(lambda file: file.endswith('.jpg'), os.listdir(path_img)))\n",
    "    \n",
    "    for foto in fotos:\n",
    "        response = requests.request(\n",
    "        #method\n",
    "        'POST',\n",
    "        #url\n",
    "        BASE_URL + '/largepersongroups/' + nombre_base + '/persons/' + personId + '/persistedFaces',\n",
    "        # params\n",
    "        params = {'detectionModel': 'detection_02'},\n",
    "        #data\n",
    "        data = open(path_img + foto, 'rb').read(),\n",
    "        #headers\n",
    "        headers = {'Content-Type': 'application/octet-stream',\n",
    "                   'Ocp-Apim-Subscription-Key': KEY}\n",
    "        )\n",
    "       \n",
    "    print('Finaliza la carga de las fotos de ' + usuario)\n",
    "    time.sleep(30)\n",
    "\n",
    "# Revisamos los usuarios cargados:\n",
    "response = requests.request(\n",
    "    #method\n",
    "    'GET',\n",
    "    #url\n",
    "    BASE_URL + '/largepersongroups/' + nombre_base + '/persons',\n",
    "    #headers\n",
    "    headers = {'Content-Type': 'application/json',\n",
    "               'Ocp-Apim-Subscription-Key': KEY}\n",
    ")\n",
    "\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto termina el ejemplo/ejercicio, pero se usará esta base de rostros para los que resta del tutorial.\n",
    "\n",
    "---\n",
    "\n",
    "13. Ahora es necesario entrenar la base de datos para que pueda identificar a las personas en ellas.\n",
    "\n",
    "### LargePersonGroup - Train\n",
    "\n",
    "Submit a large person group training task. Training is a crucial step that only a trained large person group can be used by Face - Identify.\n",
    "\n",
    "The training task is an asynchronous task. Training time depends on the number of person entries, and their faces in a large person group. It could be in several seconds, or up to half a hour for 1,000,000 persons. To check training completion, please use LargePersonGroup - Get Training Status.\n",
    "\n",
    "#### Http Method\n",
    "POST\n",
    "\n",
    "#### Request URL\n",
    "\n",
    "https://{endpoint}/face/v1.0/largepersongroups/{largePersonGroupId}/train\n",
    "\n",
    "#### Request parameters\n",
    "\n",
    "| Field | Type | Description |\n",
    "|:--- |:---:|:--- |\n",
    "| largePersonGroupId | string | Target large person group to be trained. |\n",
    "\n",
    "#### Request headers\n",
    "\n",
    "| Field | Type | Description |\n",
    "|:--- |:---:|:--- |\n",
    "| Ocp-Apim-Subscription-Key | string | Subscription key which provides access to this API. Found in your Cognitive Services accounts. |\n",
    "\n",
    "#### Request body\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.request(\n",
    "    #method\n",
    "    'POST',\n",
    "    #url\n",
    "    BASE_URL + '/largepersongroups/' + nombre_base + '/train',\n",
    "    #headers\n",
    "    headers = {'Ocp-Apim-Subscription-Key': KEY}\n",
    ")\n",
    "\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. En este caso, de acuerdo con la documentación, un código **202** indica una respuesta exitosa y no regresa información en el JSON.\n",
    "\n",
    "15. Sin embargo, es posible ver el estado de la base de datos usando el llamado para **get trainning status**, el cual vimos previamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.request(\n",
    "    #method\n",
    "    'GET',\n",
    "    #url\n",
    "    BASE_URL + '/largepersongroups/' + nombre_base + '/training',\n",
    "    #headers\n",
    "    headers = {'Ocp-Apim-Subscription-Key': KEY}\n",
    ")\n",
    "\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. Ahora obtenemos una respuesta **200** (diferente a la 404 inicial). Esto implica que el entrenamiento fue correcto.\n",
    "\n",
    "17. Podemos obtener más información revisando la respuesta del JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'succeeded',\n",
       " 'createdDateTime': '2019-10-18T16:44:10.152627Z',\n",
       " 'lastActionDateTime': '2019-10-18T16:44:10.3400568Z',\n",
       " 'message': None,\n",
       " 'lastSuccessfulTrainingDateTime': '2019-10-18T16:44:10.3400568Z'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18. En el JSON previo observamos el status **succeeded** y nos da fecha y tiempo en que se creo la base, se realizó algún cambio y la última vez que fue entrenado exitosamente.\n",
    "\n",
    "19. Ahora, con la base entrenada, podemos comenzar a comparar rostros de otras fotos.\n",
    "\n",
    "### Face - Detect\n",
    "\n",
    "Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.\n",
    "\n",
    "- No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in Face - Identify, Face - Verify, and Face - Find Similar. The stored face features will expire and be deleted 24 hours after the original detection call.\n",
    "- Optional parameters include faceId, landmarks, and attributes. Attributes include age, gender, headPose, smile, facialHair, glasses, emotion, hair, makeup, occlusion, accessories, blur, exposure and noise. Some of the results returned for specific attributes may not be highly accurate.\n",
    "- JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\n",
    "- The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\n",
    "- Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.\n",
    "- For optimal results when querying Face - Identify, Face - Verify, and Face - Find Similar ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).\n",
    "- Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to How to specify a detection model\n",
    "    - 'detection_01': The default detection model for Face - Detect. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\n",
    "    - 'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. Face attributes and landmarks are disabled if you choose this detection model.\n",
    "- Different 'recognitionModel' values are provided. If follow-up operations like Verify, Identify, Find Similar are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to How to specify a recognition model.\n",
    "    - 'recognition_01': The default recognition model for Face - Detect. All those faceIds created before 2019 March are bonded with this recognition model.\n",
    "    - 'recognition_02': Recognition model released in 2019 March. 'recognition_02' is recommended since its overall accuracy is improved compared with 'recognition_01'.\n",
    "\n",
    "#### Http Method\n",
    "POST\n",
    "\n",
    "#### Request URL\n",
    "\n",
    "https://{endpoint}/face/v1.0/detect[?returnFaceId][&returnFaceLandmarks][&returnFaceAttributes][&recognitionModel][&returnRecognitionModel][&detectionModel]\n",
    "\n",
    "\n",
    "#### Request parameters\n",
    "\n",
    "| Field | Type | Description |\n",
    "|:--- |:---:|:--- |\n",
    "| returnFaceId (optional) | boolean | Return faceIds of the detected faces or not. The default value is true. |\n",
    "| returnFaceLandmarks (optional) | boolean | Return face landmarks of the detected faces or not. The default value is false. |\n",
    "| returnFaceAttributes (optional) | string | Analyze and return the one or more specified face attributes in the comma-separated string like \"returnFaceAttributes=age,gender\". Supported face attributes include age, gender, headPose, smile, facialHair, glasses, emotion, hair, makeup, occlusion, accessories, blur, exposure and noise. Face attribute analysis has additional computational and time cost. |\n",
    "| recognitionModel (optional) | string | The 'recognitionModel' associated with the detected faceIds. Supported 'recognitionModel' values include \"recognition_01\" or \"recognition_02\". The default value is \"recognition_01\". \"recognition_02\" is recommended since its overall accuracy is improved compared with \"recognition_01\". |\n",
    "| returnRecognitionModel (optional) | boolean | Return 'recognitionModel' or not. The default value is false. |\n",
    "| detectionModel (optional) | string | The 'detectionModel' associated with the detected faceIds. Supported 'detectionModel' values include \"detection_01\" or \"detection_02\". The default value is \"detection_01\". |\n",
    "\n",
    "#### Request headers\n",
    "\n",
    "| Field | Type | Description |\n",
    "|:--- |:---:|:--- |\n",
    "| Content-Type | string | Media type of the body sent to the API. |\n",
    "| Ocp-Apim-Subscription-Key | string | Subscription key which provides access to this API. Found in your Cognitive Services accounts. |\n",
    "\n",
    "#### Request body\n",
    "\n",
    "To detect in a URL (or binary data) specified image.\n",
    "\n",
    "JSON fields in the request body:\n",
    "\n",
    "| Field | Type | Description |\n",
    "|:--- |:---:|:--- |\n",
    "| url | String | URL of input image. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.request(\n",
    "    #method\n",
    "    'POST',\n",
    "    #url\n",
    "    BASE_URL + '/detect',\n",
    "    #params\n",
    "    params = {'returnFaceId': True,\n",
    "              'returnFaceLandmarks': False,\n",
    "              'recognitionModel': 'recognition_02'},\n",
    "    #data\n",
    "    data = open('foto_06.jpg', 'rb').read(),\n",
    "    #headers\n",
    "    headers = {'Content-Type': 'application/octet-stream',\n",
    "               'Ocp-Apim-Subscription-Key': KEY}\n",
    ")\n",
    "\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20. Obteniendo una respuesta correcta, procedemos a extraer el 'faceId' generado para poder hacer las comparaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'faceId': 'de2ac956-c885-4221-af25-a21ec6ebcf27', 'faceRectangle': {'top': 45, 'left': 96, 'width': 90, 'height': 90}}]\n"
     ]
    }
   ],
   "source": [
    "print(response.json())\n",
    "\n",
    "faceId = response.json()[0]['faceId']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21. En este caso utilizaremos el servicio de **identify** para comparar este nuevo rostro respecto a los usuarios de la base de datos generada previamente.\n",
    "\n",
    "### Face - Identify\n",
    "\n",
    "1-to-many identification to find the closest matches of the specific query person face from a person group or large person group.\n",
    "\n",
    "For each face in the faceIds array, Face Identify will compute similarities between the query face and all the faces in the person group (given by personGroupId) or large person group (given by largePersonGroupId), and return candidate person(s) for that face ranked by similarity confidence. The person group/large person group should be trained to make it ready for identification. See more in PersonGroup - Train and LargePersonGroup - Train.\n",
    "\n",
    "Remarks:\n",
    "- The algorithm allows more than one face to be identified independently at the same request, but no more than 10 faces.\n",
    "- Each person in the person group/large person group could have more than one face, but no more than 248 faces.\n",
    "- Higher face image quality means better identification precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.\n",
    "- Number of candidates returned is restricted by maxNumOfCandidatesReturned and confidenceThreshold. If no person is identified, the returned candidates will be an empty array.\n",
    "- Try Face - Find Similar when you need to find similar faces from a face list/large face list instead of a person group/large person group.\n",
    "- The 'recognitionModel' associated with the query faces' faceIds should be the same as the 'recognitionModel' used by the target person group or large person group.\n",
    "\n",
    "#### Http Method\n",
    "\n",
    "POST\n",
    "\n",
    "#### Request URL\n",
    "\n",
    "https://{endpoint}/face/v1.0/identify\n",
    "\n",
    "#### Request headers\n",
    "\n",
    "| Field | Type | Description |\n",
    "|:--- |:---:|:--- |\n",
    "| Content-Type | string | Media type of the body sent to the API. |\n",
    "| Ocp-Apim-Subscription-Key | string | Subscription key which provides access to this API. Found in your Cognitive Services accounts. |\n",
    "\n",
    "#### Request body\n",
    "\n",
    "JSON fields in request body:\n",
    "\n",
    "| Field | Type | Description |\n",
    "|:--- |:---:|:--- |\n",
    "| faceIds | Array | Array of query faces faceIds, created by the Face - Detect. Each of the faces are identified independently. The valid number of faceIds is between [1, 10]. |\n",
    "| personGroupId | String | personGroupId of the target person group, created by PersonGroup - Create. Parameter personGroupId and largePersonGroupId should not be provided at the same time. |\n",
    "| largePersonGroupId | String | largePersonGroupId of the target large person group, created by LargePersonGroup - Create. Parameter personGroupId and largePersonGroupId should not be provided at the same time. |\n",
    "| maxNumOfCandidatesReturned (optional) | Number | The range of maxNumOfCandidatesReturned is between 1 and 100 (default is 10). |\n",
    "| confidenceThreshold (optional) | Number | Optional parameter. Customized identification confidence threshold, in the range of [0, 1]. Advanced user can tweak this value to override default internal threshold for better precision on their scenario data. Note there is no guarantee of this threshold value working on other data and after algorithm updates. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.request(\n",
    "    #method\n",
    "    'POST',\n",
    "    #url\n",
    "    BASE_URL + '/identify',\n",
    "    #json\n",
    "    json = {'faceIds': [faceId],\n",
    "            'largePersonGroupId': nombre_base},\n",
    "    #headers\n",
    "    headers = {'Content-Type': 'application/json',\n",
    "               'Ocp-Apim-Subscription-Key': KEY}\n",
    ")\n",
    "\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22. Obtenemos una respuesta **200**, lo cual implica que el proceso de comparación finalizó de forma correcta. Ahora solo falta revisa si encontró o no alguna similitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'faceId': 'de2ac956-c885-4221-af25-a21ec6ebcf27', 'candidates': [{'personId': '48819917-a770-47d8-9c52-a807f9b7aee5', 'confidence': 0.90931}]}]\n"
     ]
    }
   ],
   "source": [
    "print(response.json())\n",
    "\n",
    "id_similar = response.json()[0]['candidates'][0]['personId']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23. La respuesta del API nos indica que existe una similitud del 0.91 respecto a un candidato. Sin embargo nos entrega el Id del usuario. Por lo que tendrémos que extraer la información del nombre. Usaremos el **person list** para este proposito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emilia_clarke\n"
     ]
    }
   ],
   "source": [
    "response = requests.request(\n",
    "    #method\n",
    "    'GET',\n",
    "    #url\n",
    "    BASE_URL + '/largepersongroups/' + nombre_base + '/persons',\n",
    "    #headers\n",
    "    headers = {'Content-Type': 'application/json',\n",
    "               'Ocp-Apim-Subscription-Key': KEY}\n",
    ")\n",
    "\n",
    "for usuario in response.json():\n",
    "    if usuario['personId'] in id_similar:\n",
    "        print(usuario['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Ejercicio\n",
    "\n",
    "1. Usar las imágenes en la carpeta de prueba y verficar si encuentra similitudes con los usuarios dados de alta.\n",
    "    - ¿Logró identificar todos los rostros de las imágenes utilizadas?\n",
    "    - ¿Encontró similitudes en todos ellos?\n",
    "\n",
    "2. Buscar más imagenes en internet y actualizar la base de datos con nuevos usuarios y/o más imágenes de los usuarios existentes.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/end.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
